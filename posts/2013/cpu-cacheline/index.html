<!DOCTYPE html>
<html>

<head>
    
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">

<meta name="description" content="石头的博客.">
<title>
    Nginx - CPU Cacheline 深思 - Oopschen的日志
</title>


<link rel="shortcut icon" href="/sam.ico">








<link rel="stylesheet" href="/css/main.min.3c9fa6b3264a9f8be4f27730f1d5f0ded496304d03812ed49d97703ffb28122a.css" integrity="sha256-PJ&#43;msyZKn4vk8ncw8dXw3tSWME0DgS7UnZdwP/soEio=" crossorigin="anonymous" media="screen">





<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Didact+Gothic">



  <script data-ad-client="ca-pub-9689498343252538" async
    src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Nginx - CPU Cacheline 深思"/>
<meta name="twitter:description" content="在nginx的内存管理,我们会看到ngx_align_ptr这样的代码,从命名上来看是对指针地址的对齐操作。为什么要这么做呢？不是增加负担么？带着这样的问题,我们来看看CPU cache这个很有深度的问题。这篇博客是对drepper的理解和消化,有英文阅读能力的可以直接参考原文,跳过此博客。（PS：人家2007年写的,惭愧惭愧)
内存硬件操作 这里的内存只是对同步的DRAM进行表述,对于其他的内存类型不适用。
内存的所有操作都是由内存控制器完成,而当下内存采用行列模式,管理硬件内存地址。也就是说,当内存控制器读取或写入数据的时候,会有3步操作:
 precharge, 对内存充电操作 RAS, 对行的选择 CAS, 对列的选择  最后才能开始读取或写入这个单元的数据, 然而这几个操作相对cpu的运行速度是很慢很慢的。所以出于充分利用cpu的目的,硬件发展中在cpu中加入了L1,L2,L3的缓存。每级缓存的访问速度是递减的,而容量是递增的,他们的访问速度都是内存的10倍以上。这样CPU不用等待缓慢的内存数据,而直接从高速的缓存中取。也就是说缓存的命中率决定CPU的效率。同时,对内存的读取和写入也不视一个字节一个字节写入,而是一串字节,我们通常称为cache line。这样的设计是基于相邻的东西更有可能被使用的原则,这样也就提高了CPU的利用率。
Cache line 首先我们来看看Cache line的结构：
 tag,用于区分不同内存地址的标签 set,用于在tag中选择不同的集合 offseet, 用于一个cache line中开始的位置  如上面说内存每访问一个地址都会一并把cache line大小的数据从ram中读取到缓存中。那么,当cpu读取数据的时候首先会从缓存中取,而这个取的速度必须很快,不然就失去了缓存的意义。因此,缓存的大小都很小,这也是出于对速度的要求,因为对大量的缓存比对需要很多时间。
这个时候人们总会用索引的方式,加快比对,这也就是上述结构的意义。CPU用set过滤出一小部分的地址,然后用offset和tag比对是否为请求的数据。
通过cache line的实现,CPU实现了预提取数据的功能。当然如果那个原则被打破,这样的设计也是低效的。
实践 理论虽如此,我们来看看实际代码表现如何？
cache line大小 首先要解决的问题就是获取CPU cache line的大小。我们以linux为例：
cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size 这个文件记录了CPU的cache line大小,单位是字节。这个文件的目录下还存在着一些其他文件
 coherency_line_size
level
number_of_sets
physical_line_partition
shared_cpu_list
shared_cpu_map
size
type
ways_of_associativity
 这些文件分别说明了缓存的类型,等级,几路set和共享缓存的CPU等等信息
代码论证 既然缓存只是提高了CPU获取速度的速度,那么我们可以设计如下的代码来检验这个理论。
 CPU按字节对内存进行访问 不同的代码分配到不同的CPU核上去,减少系统调度带来的干扰 对比组为缓存对齐的指针和随机的指针  缓存对齐的代码 #define _GNU_SOURCE  #include &lt;sched.h&gt; #include &lt;stdlib.h&gt; #include &lt;stdint."/>

<meta property="og:title" content="Nginx - CPU Cacheline 深思" />
<meta property="og:description" content="在nginx的内存管理,我们会看到ngx_align_ptr这样的代码,从命名上来看是对指针地址的对齐操作。为什么要这么做呢？不是增加负担么？带着这样的问题,我们来看看CPU cache这个很有深度的问题。这篇博客是对drepper的理解和消化,有英文阅读能力的可以直接参考原文,跳过此博客。（PS：人家2007年写的,惭愧惭愧)
内存硬件操作 这里的内存只是对同步的DRAM进行表述,对于其他的内存类型不适用。
内存的所有操作都是由内存控制器完成,而当下内存采用行列模式,管理硬件内存地址。也就是说,当内存控制器读取或写入数据的时候,会有3步操作:
 precharge, 对内存充电操作 RAS, 对行的选择 CAS, 对列的选择  最后才能开始读取或写入这个单元的数据, 然而这几个操作相对cpu的运行速度是很慢很慢的。所以出于充分利用cpu的目的,硬件发展中在cpu中加入了L1,L2,L3的缓存。每级缓存的访问速度是递减的,而容量是递增的,他们的访问速度都是内存的10倍以上。这样CPU不用等待缓慢的内存数据,而直接从高速的缓存中取。也就是说缓存的命中率决定CPU的效率。同时,对内存的读取和写入也不视一个字节一个字节写入,而是一串字节,我们通常称为cache line。这样的设计是基于相邻的东西更有可能被使用的原则,这样也就提高了CPU的利用率。
Cache line 首先我们来看看Cache line的结构：
 tag,用于区分不同内存地址的标签 set,用于在tag中选择不同的集合 offseet, 用于一个cache line中开始的位置  如上面说内存每访问一个地址都会一并把cache line大小的数据从ram中读取到缓存中。那么,当cpu读取数据的时候首先会从缓存中取,而这个取的速度必须很快,不然就失去了缓存的意义。因此,缓存的大小都很小,这也是出于对速度的要求,因为对大量的缓存比对需要很多时间。
这个时候人们总会用索引的方式,加快比对,这也就是上述结构的意义。CPU用set过滤出一小部分的地址,然后用offset和tag比对是否为请求的数据。
通过cache line的实现,CPU实现了预提取数据的功能。当然如果那个原则被打破,这样的设计也是低效的。
实践 理论虽如此,我们来看看实际代码表现如何？
cache line大小 首先要解决的问题就是获取CPU cache line的大小。我们以linux为例：
cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size 这个文件记录了CPU的cache line大小,单位是字节。这个文件的目录下还存在着一些其他文件
 coherency_line_size
level
number_of_sets
physical_line_partition
shared_cpu_list
shared_cpu_map
size
type
ways_of_associativity
 这些文件分别说明了缓存的类型,等级,几路set和共享缓存的CPU等等信息
代码论证 既然缓存只是提高了CPU获取速度的速度,那么我们可以设计如下的代码来检验这个理论。
 CPU按字节对内存进行访问 不同的代码分配到不同的CPU核上去,减少系统调度带来的干扰 对比组为缓存对齐的指针和随机的指针  缓存对齐的代码 #define _GNU_SOURCE  #include &lt;sched.h&gt; #include &lt;stdlib.h&gt; #include &lt;stdint." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://oopschen.github.io/posts/2013/cpu-cacheline/" />
<meta property="article:published_time" content="2013-09-01T19:38:24+00:00" />
<meta property="article:modified_time" content="2013-09-01T19:38:24+00:00" />


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-49453400-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


    

    
    
    
    <title>
        
        Nginx - CPU Cacheline 深思
        
    </title>
</head>

<body>
    
    
    <header class="wrap flex-container">
        <h1>Nginx - CPU Cacheline 深思</h1>
    </header>
    
    <main class="wrap">
        
<div class="flex-container">
    <aside role="complementary">
        Sun Sep 01, 2013 &#183; 293 words
        <div class="tag-container">
            
            
            <span class="tag">
                <a href="/tags/nginx/">
                    nginx
                </a>
            </span>
            
            
            
            <span class="tag">
                <a href="/tags/cache/">
                    cache
                </a>
            </span>
            
            
            
            <span class="tag">
                <a href="/tags/cpu/">
                    cpu
                </a>
            </span>
            
            
        </div>
    </aside>
    <hr />
    <article role="article">
        <p>在nginx的内存管理,我们会看到<em>ngx_align_ptr</em>这样的代码,从命名上来看是对指针地址的对齐操作。为什么要这么做呢？不是增加负担么？带着这样的问题,我们来看看CPU cache这个很有深度的问题。这篇博客是对<a href="http://www.akkadia.org/drepper/cpumemory.pdf" title="原作">drepper</a>的理解和消化,有英文阅读能力的可以直接参考原文,跳过此博客。（PS：人家2007年写的,惭愧惭愧)</p>
<h4 id="内存硬件操作">内存硬件操作</h4>
<p>这里的内存只是对同步的DRAM进行表述,对于其他的内存类型不适用。<br>
内存的所有操作都是由内存控制器完成,而当下内存采用行列模式,管理硬件内存地址。也就是说,当内存控制器读取或写入数据的时候,会有3步操作:</p>
<ol>
<li>precharge, 对内存充电操作</li>
<li>RAS, 对行的选择</li>
<li>CAS, 对列的选择</li>
</ol>
<p>最后才能开始读取或写入这个单元的数据, 然而这几个操作相对cpu的运行速度是很慢很慢的。所以出于充分利用cpu的目的,硬件发展中在cpu中加入了L1,L2,L3的缓存。每级缓存的访问速度是递减的,而容量是递增的,他们的访问速度都是内存的10倍以上。这样CPU不用等待缓慢的内存数据,而直接从高速的缓存中取。也就是说缓存的命中率决定CPU的效率。同时,对内存的读取和写入也不视一个字节一个字节写入,而是一串字节,我们通常称为<strong>cache line</strong>。这样的设计是基于相邻的东西更有可能被使用的原则,这样也就提高了CPU的利用率。</p>
<h4 id="cache-line">Cache line</h4>
<p>首先我们来看看Cache line的结构：</p>
<ol>
<li>tag,用于区分不同内存地址的标签</li>
<li>set,用于在tag中选择不同的集合</li>
<li>offseet, 用于一个cache line中开始的位置</li>
</ol>
<p>如上面说内存每访问一个地址都会一并把cache line大小的数据从ram中读取到缓存中。那么,当cpu读取数据的时候首先会从缓存中取,而这个取的速度必须很快,不然就失去了缓存的意义。因此,缓存的大小都很小,这也是出于对速度的要求,因为对大量的缓存比对需要很多时间。<br>
这个时候人们总会用索引的方式,加快比对,这也就是上述结构的意义。CPU用set过滤出一小部分的地址,然后用offset和tag比对是否为请求的数据。<br>
通过cache line的实现,CPU实现了预提取数据的功能。当然如果那个原则被打破,这样的设计也是低效的。</p>
<h4 id="实践">实践</h4>
<p>理论虽如此,我们来看看实际代码表现如何？</p>
<h5 id="cache-line大小">cache line大小</h5>
<p>首先要解决的问题就是获取CPU cache line的大小。我们以linux为例：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Bash" data-lang="Bash">    cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size   
</code></pre></div><p>这个文件记录了CPU的cache line大小,单位是字节。这个文件的目录下还存在着一些其他文件</p>
<blockquote>
<p>coherency_line_size<br>
level<br>
number_of_sets<br>
physical_line_partition<br>
shared_cpu_list<br>
shared_cpu_map<br>
size<br>
type<br>
ways_of_associativity</p>
</blockquote>
<p>这些文件分别说明了缓存的类型,等级,几路set和共享缓存的CPU等等信息</p>
<h5 id="代码论证">代码论证</h5>
<p>既然缓存只是提高了CPU获取速度的速度,那么我们可以设计如下的代码来检验这个理论。</p>
<ol>
<li>CPU按字节对内存进行访问</li>
<li>不同的代码分配到不同的CPU核上去,减少系统调度带来的干扰</li>
<li>对比组为缓存对齐的指针和随机的指针</li>
</ol>
<h5 id="缓存对齐的代码">缓存对齐的代码</h5>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c">    <span style="color:#75715e">#define _GNU_SOURCE
</span><span style="color:#75715e"></span>    <span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;sched.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
    <span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdlib.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>    <span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdint.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>    <span style="color:#75715e">#define ngx_align_ptr(p, a)                                                   \
</span><span style="color:#75715e">        (u_char *) (((uintptr_t) (p) + ((uintptr_t) a - 1)) &amp; ~((uintptr_t) a - 1))
</span><span style="color:#75715e"></span>    <span style="color:#75715e">#define CACHELINE_SIZE_BYTES 64
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// 10M
</span><span style="color:#75715e"></span>    <span style="color:#75715e">#define TOTOAL_SIZE_BYTES 10485760
</span><span style="color:#75715e"></span>
    <span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>() {
      cpu_set_t cpuset;
      CPU_ZERO(<span style="color:#f92672">&amp;</span>cpuset);
      CPU_SET(<span style="color:#ae81ff">0</span>, <span style="color:#f92672">&amp;</span>cpuset);
      sched_setaffinity(<span style="color:#ae81ff">0</span>, <span style="color:#66d9ef">sizeof</span>(cpu_set_t), <span style="color:#f92672">&amp;</span>cpuset);

      <span style="color:#75715e">// malloc ptr
</span><span style="color:#75715e"></span>      uint8_t <span style="color:#f92672">*</span> ptr, <span style="color:#f92672">*</span> alignedPtr;
      uint32_t i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
      <span style="color:#66d9ef">int</span> ret <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
      uint32_t size <span style="color:#f92672">=</span> (CACHELINE_SIZE_BYTES <span style="color:#f92672">+</span> TOTOAL_SIZE_BYTES) <span style="color:#f92672">/</span> <span style="color:#66d9ef">sizeof</span>(uint8_t),
               loopSize <span style="color:#f92672">=</span> TOTOAL_SIZE_BYTES <span style="color:#f92672">/</span> <span style="color:#66d9ef">sizeof</span>(uint8_t);
      ptr <span style="color:#f92672">=</span> calloc(size, <span style="color:#66d9ef">sizeof</span>(uint8_t));
      <span style="color:#66d9ef">if</span> (<span style="color:#f92672">!</span>ptr) {
        <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">1</span>;
      }

      <span style="color:#75715e">// align ptr
</span><span style="color:#75715e"></span>      alignedPtr <span style="color:#f92672">=</span> ngx_align_ptr(ptr, CACHELINE_SIZE_BYTES);

      <span style="color:#75715e">// loop till end
</span><span style="color:#75715e"></span>      <span style="color:#66d9ef">for</span> (; i<span style="color:#f92672">&lt;</span>loopSize <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>; i<span style="color:#f92672">++</span>) {
        ret <span style="color:#f92672">+=</span> alignedPtr[i];
      }
      free(ptr);
      <span style="color:#66d9ef">return</span> ret;
    }
</code></pre></div><h5 id="随机的指针">随机的指针</h5>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c">    <span style="color:#75715e">#define _GNU_SOURCE
</span><span style="color:#75715e"></span>    <span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;sched.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
    <span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdlib.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>    <span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdint.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>    <span style="color:#75715e">#define ngx_align_ptr(p, a)                                                   \
</span><span style="color:#75715e">      (u_char *) (((uintptr_t) (p) + ((uintptr_t) a - 1)) &amp; ~((uintptr_t) a - 1))
</span><span style="color:#75715e"></span>    <span style="color:#75715e">#define CACHELINE_SIZE_BYTES 64
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// 10M
</span><span style="color:#75715e"></span>    <span style="color:#75715e">#define TOTOAL_SIZE_BYTES 10485760
</span><span style="color:#75715e"></span>
    <span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>() {
      cpu_set_t cpuset;
      CPU_ZERO(<span style="color:#f92672">&amp;</span>cpuset);
      CPU_SET(<span style="color:#ae81ff">1</span>, <span style="color:#f92672">&amp;</span>cpuset);
      sched_setaffinity(<span style="color:#ae81ff">0</span>, <span style="color:#66d9ef">sizeof</span>(cpu_set_t), <span style="color:#f92672">&amp;</span>cpuset);

      <span style="color:#75715e">// malloc ptr
</span><span style="color:#75715e"></span>      uint8_t <span style="color:#f92672">*</span> ptr, <span style="color:#f92672">*</span> alignedPtr;
      uint32_t i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
      <span style="color:#66d9ef">int</span> ret <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
      uint32_t size <span style="color:#f92672">=</span> (CACHELINE_SIZE_BYTES <span style="color:#f92672">+</span> TOTOAL_SIZE_BYTES) <span style="color:#f92672">/</span> <span style="color:#66d9ef">sizeof</span>(uint8_t),
               loopSize <span style="color:#f92672">=</span> TOTOAL_SIZE_BYTES <span style="color:#f92672">/</span> <span style="color:#66d9ef">sizeof</span>(uint8_t);
      ptr <span style="color:#f92672">=</span> calloc(size, <span style="color:#66d9ef">sizeof</span>(uint8_t));
      <span style="color:#66d9ef">if</span> (<span style="color:#f92672">!</span>ptr) {
        <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">1</span>;
      }

      <span style="color:#75715e">// align ptr
</span><span style="color:#75715e"></span>      alignedPtr <span style="color:#f92672">=</span> ptr;

      <span style="color:#75715e">// loop till end
</span><span style="color:#75715e"></span>      <span style="color:#66d9ef">for</span> (; i<span style="color:#f92672">&lt;</span>loopSize <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>; i<span style="color:#f92672">++</span>) {
        ret <span style="color:#f92672">+=</span> alignedPtr[i];
      }
      free(ptr);
      <span style="color:#66d9ef">return</span> ret;
    }
</code></pre></div><h5 id="运行结果">运行结果</h5>
<p>我们用如下命令编译:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Bash" data-lang="Bash">    clang -Wall -O2 xxx.c -o xxx
</code></pre></div><p>这里我们不用优化,因为优化会将循环拉取的代码简化,达不到实验效果。最终我们用<strong>time -p</strong>检测效率,缓存对齐的代码快了一倍。这就是效率的提升。</p>
<h4 id="总结">总结</h4>
<p>通过上面理论的理解和实验的结果,我们可以在编程的时候做如下考虑：</p>
<ol>
<li>数据类型在设计的时候,可以和cache line对齐</li>
<li>访问数据类型的时候,按定义的顺序访问,以减少不必要的缓存不命中</li>
<li>对遍历的情景,我们可以采用这种方式,提高效率</li>
</ol>
<p>当然计算机的世界没有万金油,这种方式并不适合觉多多数的场景,memcache就没有采用这种方式。个人猜想大概是因为,memcache的场景都是离散随机的,并不会因为cache line而提升效率,反而会因为这种方式带来的内存碎片降低效果。</p>

    </article>
</div>


        
<nav role="navigation" class="flex-container bottom-menu">
    
<hr />
<p>


    
        <a href="/posts">back</a>
        
            &#183;
        
    

    
        
            <a href="/posts">博客日志</a>
        
    
    
        
            &#183; 
            <a href="/about">我是谁?</a>
        
    
    &#183; 
    <a href="/">
        主页
    </a>

</p>
</nav>

    </main>
    
    <footer class="flex-container footer">石头, OOPS!!!
</footer>
    
    
</body>

</html>